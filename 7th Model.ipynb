{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data=pd.read_csv('IMDBDataset.csv')\n",
    "\n",
    "train = imdb_data[:10000]\n",
    "test = imdb_data[40000:45000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def tokenize(data):\n",
    "    corpus = [word_tokenize(token) for token in data]\n",
    "    lowercase_train = [[token.lower() for token in doc] for doc in corpus]\n",
    "    alphas = [[token for token in doc if token.isalpha()] for doc in lowercase_train]\n",
    "    stop_words = stopwords.words('english')\n",
    "    train_no_stop = [[token for token in doc if token not in stop_words] for doc in alphas]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [[stemmer.stem(token) for token in doc] for doc in train_no_stop]\n",
    "    train_clean_str = [ ' '.join(doc) for doc in stemmed]\n",
    "    return train_clean_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wonder littl product br br film techniqu fashion give comfort sometim discomfort sens realism entir piec br br actor extrem well michael sheen got polari voic pat truli see seamless edit guid refer william diari entri well worth watch terrificli written perform piec master product one great master comedi life br br realism realli come home littl thing fantasi guard rather use tradit techniqu remain solid disappear play knowledg sens particularli scene concern orton halliwel set particularli flat halliwel mural decor everi surfac terribl well done'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=imdb_data.review[:10000]\n",
    "y_train=imdb_data.sentiment[:10000]\n",
    "\n",
    "X_train = tokenize(X_train)\n",
    "\n",
    "X_test2=imdb_data.review[40000:45000]\n",
    "y_test2=imdb_data.sentiment[40000:45000]\n",
    "\n",
    "X_test2 = tokenize(X_test2)\n",
    "y_test2 = y_test2.values.tolist()\n",
    "\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-527945be3403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mElasticNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtraTreesRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#from sklearn.neural_network import MLPRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import BayesianRidge, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "#from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory = [\n",
    " RandomForestRegressor(),\n",
    " XGBRegressor(nthread=1),\n",
    " #MLPRegressor(),\n",
    " Ridge(),\n",
    " BayesianRidge(),\n",
    " ExtraTreesRegressor(),\n",
    " ElasticNet(),\n",
    " KNeighborsRegressor(),\n",
    " GradientBoostingRegressor()\n",
    "]\n",
    "\n",
    "for model in model_factory:\n",
    " model.seed = 42\n",
    " num_folds = 3\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='neg_mean_squared_error')\n",
    " score_description = \" %0.2f (+/- %0.2f)\" % (np.sqrt(scores.mean()*-1), scores.std() * 2)\n",
    "\n",
    "print('{model:25} CV-5 RMSE: {score}'.format(\n",
    " model=model.__class__.__name__,\n",
    " score=score_description\n",
    " ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
